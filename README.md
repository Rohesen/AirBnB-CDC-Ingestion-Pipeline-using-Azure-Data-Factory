# AirBnB CDC Processing ğŸš€

This project demonstrates a **Change Data Capture (CDC) data pipeline** for Airbnb-like booking data using **Azure services**.
The pipeline ingests customer and booking data, performs transformations, and stores it in **Azure Synapse Analytics** for reporting and analytics.

---

## ğŸ“Œ Architecture

```mermaid
flowchart LR
    subgraph ADLS
        CData[Customer Data<br/>Cust-yyyy-mm-dd-hh]
    end
    
    subgraph CosmosDB
        BData[Bookings Collection]
    end
    
    App[AirBnB App] --> CosmosDB
    
    subgraph ADF [Azure Data Factory]
        direction TB
        P1[Pipeline 1 <br/> Load Customer Dim]
        P2[Pipeline 2<br/>Booking Data + Aggregation]
        P3[Pipeline 3<br/>Orchestration]
    end
    
    ADLS --> P1 --> Synapse[(Azure Synapse DW)]
    CosmosDB --> P2 --> Synapse
    
    P3 --> P1
    P3 --> P2
    P2 --> StoredProc[(Stored Procedure)]
```

---

## âš™ï¸ Tech Stack

* **Python** â€“ Mock data generation for Cosmos DB
* **Azure Cosmos DB** â€“ Source for real-time bookings CDC
* **Azure Data Lake Storage (ADLS Gen2)** â€“ Customer data storage (raw + archive)
* **Azure Data Factory (ADF)** â€“ ETL orchestration and dataflows
* **Azure Synapse Analytics** â€“ Data warehouse for dimensions, facts, and aggregations
* **SQL** â€“ Schema design, stored procedures, aggregations
* **Faker** â€“ Fake data generator for testing

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ mock_data_in_cosmosdb.py     # Python script to generate mock booking data
â”œâ”€â”€ synapse_tables.sql           # DDL for Synapse tables & stored procedures
â”œâ”€â”€ adf/                         # JSON export of ADF pipelines (if exported)
â”œâ”€â”€ README.md                    # Documentation
```

---

## ğŸ› ï¸ Setup Instructions

### 1. Cosmos DB â€“ Mock Data Generation

Run the script to insert **real-time booking events** into Cosmos DB.

```bash
pip install azure-cosmos faker
python mock_data_in_cosmosdb.py
```

This will generate bookings with fields like:

* `booking_id`, `customer_id`, `property_id`, `check_in_date`, `check_out_date`, `amount`, `currency`, `location`, `timestamp`

---

### 2. Synapse â€“ Schema Setup

Run the SQL script in **Synapse dedicated SQL pool**:

```sql
-- Create schema
CREATE SCHEMA airbnb;

-- Dimension table
CREATE TABLE airbnb.customer_dim (...);

-- Fact table
CREATE TABLE airbnb.bookings_fact (...);

-- Aggregation table + stored procedure
CREATE TABLE airbnb.BookingCustomerAggregation AS ...
CREATE PROCEDURE airbnb.BookingAggregation AS ...
```

---

### 3. ADLS Setup

Create a container named **`airbnb`** with:

* `customer_raw_data/` â€“ Raw customer files (CSV/Parquet)
* `customer_archive/` â€“ Archived files
* `synapse_stage/` â€“ Staging files

---

### 4. ADF Setup

Create **Linked Services**:

* `AirBnBAdls` â†’ ADLS Gen2 container `airbnb`
* `AzureSynapseAnalytics1` â†’ Synapse DWH
* `CosmosDB` â†’ Cosmos DB database `AirBnB`

Create **Datasets**:

1. `BookingDataCosmos` â†’ Cosmos container `bookings`
2. `BookingsFactData` â†’ Synapse table `bookings_fact`
3. `CustomerDataRaw` â†’ ADLS `customer_raw_data`
4. `CustomerDataArchive` â†’ ADLS `customer_archive`
5. `CustomerDataSynapse` â†’ Synapse table `customer_dim`

---

## ğŸ”„ Pipelines

### Pipeline 1 â€“ **LoadCustomerDim**

* Get Metadata (list raw customer files)
* ForEach â†’ Copy Data â†’ Upsert into `customer_dim`
* Copy Data â†’ Archive folder
* Delete Activity â†’ Remove processed raw files

### Pipeline 2 â€“ **BookingDataTransformations**

* Source: `BookingDataCosmos`
* Conditional Split: flag bad records (e.g., `check_out_date < check_in_date`)
* Derived Columns: `stay_duration`, `full_address`, `booking_year`, `booking_month`
* Lookup: compare with existing Synapse fact table
* Alter Row: decide insert/update
* Sink: `bookings_fact` (upsert mode)
* Stored Procedure: `BookingAggregation` (refresh country-level aggregations)

### Pipeline 3 â€“ **Orchestration**

* Execute **Pipeline 1**
* Execute **Pipeline 2**
* Send **Notification** (success/failure)

---

## ğŸ“Š Example Query

After the pipeline runs, aggregated results are available:

```sql
SELECT * FROM airbnb.BookingCustomerAggregation;
```

Sample output:

| Country | Total\_Bookings | Total\_Amount | Last\_Booking\_Date |
| ------- | --------------- | ------------- | ------------------- |
| USA     | 152             | 81,250.50     | 2025-09-06          |
| Germany | 73              | 32,100.00     | 2025-09-05          |
| Canada  | 91              | 45,880.00     | 2025-09-06          |

---

## ğŸš€ How to Run

1. Drop new **customer files** into `customer_raw_data/` â†’ triggers Pipeline 1
2. **Cosmos DB** change feed automatically streams new booking events â†’ Pipeline 2
3. Orchestrator (Pipeline 3) runs both pipelines and notifies upon completion

---

## âœ… Features

* Real-time **CDC ingestion** from Cosmos DB
* Incremental upserts into Synapse Fact table
* SCD-1 updates for `customer_dim`
* Data quality checks & bad record handling
* Country-level booking aggregations via stored procedure
* Automated file archival in ADLS
* Orchestrated multi-pipeline workflow

---

## ğŸ”® Future Enhancements

* Enable **Cosmos DB full-fidelity change feed** to capture deletes
* Add **Power BI dashboard** on Synapse tables
* Implement **incremental aggregations** instead of full refresh
* Replace row-level lookup with **staging + MERGE** for scale
* Use **Managed Identity** instead of keys for all linked services

---

## ğŸ‘¨â€ğŸ’» Author

Built by **\[Rohesen]** as part of a learning project on Azure Data Engineering ğŸš€

